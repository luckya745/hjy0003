import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup

# ---------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="ê°œí™”íŒŒ vs ìœ„ì •ì²™ì‚¬íŒŒ ë¶„ë¥˜ê¸°",
    page_icon="âš–ï¸",
    layout="wide"
)

st.title("âš–ï¸ ê°œí™”íŒŒ vs ìœ„ì •ì²™ì‚¬íŒŒ ë¶„ë¥˜ê¸°")
st.markdown("---")
st.info("ğŸ’¡ ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ê³ , ì–´ëŠ ì„¸ë ¥ì— ì†í• ì§€ ë¨¼ì € ì˜ˆì¸¡í•´ ë³´ì„¸ìš”!")

# ---------------------------------------------------------
# 2. API í‚¤ ì„¤ì •
# ---------------------------------------------------------
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
    # ëª¨ë¸ëª…ì€ í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì•ˆì •ì ì¸ ëª¨ë¸ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤ (ì˜ˆ: gemini-2.5-flash-lite)
    model = genai.GenerativeModel('gemini-2.5-flash-lite') 
except Exception as e:
    st.error("âš ï¸ API í‚¤ ì„¤ì • ì˜¤ë¥˜: .streamlit/secrets.toml íŒŒì¼ì— GEMINI_API_KEYê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ---------------------------------------------------------
# 3. ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜
# ---------------------------------------------------------
@st.cache_data(ttl=3600)
def scrape_history_data(name):
    """êµ­ì‚¬í¸ì°¬ìœ„ì›íšŒ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰"""
    base_url = "https://db.history.go.kr/search/searchResult.do"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://db.history.go.kr/'
    }
    params = {'searchKeyword': name, 'limit': '20'}

    try:
        response = requests.get(base_url, params=params, headers=headers, timeout=5)
        if response.status_code != 200: return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        results = []
        
        list_items = soup.select('.search_list li .cont')
        if not list_items:
            list_items = soup.select('.result_list li')

        for item in list_items[:3]:
            text = item.get_text(strip=True)
            if len(text) > 30: results.append(text)

        return " ".join(results) if results else None
    except:
        return None

def analyze_figure(name, context_text):
    """Gemini AI ë¶„ì„"""
    if context_text:
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ ê·¼ëŒ€ì‚¬ ì—­ì‚¬í•™ìì…ë‹ˆë‹¤. 
        ì•„ë˜ [ì‚¬ë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ë¬¼ '{name}'ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ì„¸ìš”.

        [ì‚¬ë£Œ]: {context_text[:2500]}
        
        [ì§€ì‹œì‚¬í•­]
        1. ì´ ì¸ë¬¼ì´ **'ê°œí™”íŒŒ(ê¸‰ì§„/ì˜¨ê±´)'**ì¸ì§€ **'ìœ„ì •ì²™ì‚¬íŒŒ'**ì¸ì§€ ëª…í™•íˆ ë¶„ë¥˜í•˜ì„¸ìš”.
        2. íŒë‹¨ ê·¼ê±°ë¥¼ ì‚¬ë£Œ ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.
        """
        source_type = "ğŸ“š ì‚¬ë£Œ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ"
    else:
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¸ë¬¼ '{name}'ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
        
        [ì§€ì‹œì‚¬í•­]
        1. ì´ ì¸ë¬¼ì´ **'ê°œí™”íŒŒ'**ì¸ì§€ **'ìœ„ì •ì²™ì‚¬íŒŒ'**ì¸ì§€ ë¶„ë¥˜í•˜ì„¸ìš”.
        2. í•´ë‹¹ íŒŒë²Œë¡œ ë¶„ë¥˜ë˜ëŠ” ê²°ì •ì ì¸ ì—­ì‚¬ì  ì‚¬ê±´ì´ë‚˜ ì£¼ì¥ì„ ì„¤ëª…í•˜ì„¸ìš”.
        """
        source_type = "ğŸ§  AI ì§€ì‹ ê¸°ë°˜ ë¶„ì„ (ì‚¬ë£Œ ê²€ìƒ‰ ì‹¤íŒ¨)"

    prompt += "\nì¶œë ¥ í˜•ì‹: ë°˜ë“œì‹œ ì²« ì¤„ì— 'ê²°ë¡ : [ê°œí™”íŒŒ/ìœ„ì •ì²™ì‚¬íŒŒ]' í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ê³ , ì´í›„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í•µì‹¬ ì´ìœ , ìƒì„¸ ë¶„ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."

    try:
        response = model.generate_content(prompt)
        return response.text, source_type
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "Error"

# ---------------------------------------------------------
# 4. í™”ë©´ êµ¬ì„± (UI)
# ---------------------------------------------------------
# ë ˆì´ì•„ì›ƒ ìˆ˜ì •: ì´ë¦„ ì…ë ¥, ì˜ˆì¸¡ ì„ íƒ, ì‹¤í–‰ ë²„íŠ¼
col1, col2, col3 = st.columns([2, 2, 1])

with col1:
    target_name = st.text_input("ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê¹€ì˜¥ê· , ìµœìµí˜„, ë¯¼ì˜ìµ")

with col2:
    # ì‚¬ìš©ìì˜ ì˜ˆì¸¡ ì…ë ¥ ë¶€ë¶„ ì¶”ê°€
    user_prediction = st.radio(
        "ë³¸ì¸ì´ ìƒê°í•˜ëŠ” ì´ ì¸ë¬¼ì˜ ì†Œì†ì€?",
        ["ê°œí™”íŒŒ", "ìœ„ì •ì²™ì‚¬íŒŒ"],
        horizontal=True,
        help="ë¶„ì„ ì‹¤í–‰ ì „ ë³¸ì¸ì˜ ì§€ì‹ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!"
    )

with col3:
    st.write("") # ê°„ê²© ë§ì¶¤ìš©
    st.write("")
    run_btn = st.button("ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True)

if run_btn and target_name:
    st.divider()
    
    # 1. ê²€ìƒ‰ ë‹¨ê³„
    with st.status("ğŸ•µï¸ ì—­ì‚¬ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...") as status:
        history_context = scrape_history_data(target_name)
        if history_context:
            status.update(label="âœ… ì‚¬ë£Œ ë°ì´í„° í™•ë³´ ì„±ê³µ!", state="complete")
        else:
            status.update(label="âš ï¸ ì‚¬ë£Œ ê²€ìƒ‰ ì‹¤íŒ¨ (AI ì§€ì‹ìœ¼ë¡œ ì „í™˜)", state="complete")
            
    # 2. ë¶„ì„ ë‹¨ê³„
    with st.spinner(f"ğŸ¤– Geminiê°€ '{target_name}'ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        result, mode = analyze_figure(target_name, history_context)

    # 3. ê²°ê³¼ ì¶œë ¥ ë° ë¹„êµ
    st.subheader(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {target_name}")
    
    # ë¹„êµ ë¡œì§: AI ê²°ê³¼ í…ìŠ¤íŠ¸ ì•ˆì— ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
    is_correct = user_prediction in result
    
    # ê²°ê³¼ ë¹„êµ ì•Œë¦¼ì°½
    if is_correct:
        st.success(f"ğŸ¯ **ë§ì•˜ìŠµë‹ˆë‹¤!** '{target_name}'ë‹˜ì€ ì‚¬ìš©ìì˜ ì˜ˆì¸¡ëŒ€ë¡œ **{user_prediction}** ì„±í–¥ì˜ ì¸ë¬¼ì…ë‹ˆë‹¤.")
    else:
        st.error(f"ğŸ§ **ì˜ˆì¸¡ê³¼ ë‹¤ë¦…ë‹ˆë‹¤.** ì‚¬ìš©ìëŠ” '{user_prediction}'ë¡œ ì˜ˆì¸¡í•˜ì…¨ìœ¼ë‚˜, ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.")

    # ìƒì„¸ ë¶„ì„ ê²°ê³¼ ë°•ìŠ¤
    with st.container(border=True):
        if "ì‚¬ë£Œ" in mode:
            st.caption(f"âœ… {mode}")
        else:
            st.caption(f"âš ï¸ {mode}")
        st.markdown(result)
    
    # ì‚¬ë£Œ ì›ë¬¸ ë³´ê¸°
    if history_context:
        with st.expander("ğŸ“œ ì°¸ê³ í•œ ì‚¬ë£Œ ì›ë¬¸ ë³´ê¸°"):
            st.text(history_context)
