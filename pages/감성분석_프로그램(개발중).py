# -*- coding: utf-8 -*-
"""감성분석 프로그램(개발중).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18etnz81nOO8-F-rCnAY4ruFVdMWNh9j2
"""

!pip install -U google-generativeai pandas matplotlib seaborn playwright
!playwright install chromium

import sys
if 'google.colab' in sys.modules:
  !echo 'debconf debconf/frontend select Noniteractive' | \
  debconf-set-selections

  # 나눔 폰트를 설치합니다.
  !sudo apt-get -qq -y install fonts-nanum
  import matplotlib.font_manager as fm
  font_files = fm.findSystemFonts(fontpaths=['/usr/share/fonts/truetype/nanum'])
  for fpath in font_files:
    fm.fontManager.addfont(fpath)

import matplotlib.pyplot as plt
plt.rc('font', family='NanumBarunGothic')
plt.rcParams['figure.dpi']=100

import google.generativeai as genai
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import asyncio
import streamlit as st  # 이 줄이 없으면 맨 위에 추가해주세요!

# 이제 실제 키 대신 '비밀 금고'를 참조합니다
GOOGLE_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)

# 1. Google AI Studio 설정
model = genai.GenerativeModel('gemini-2.5-flash')

def analyze_sentiment_with_gemini(text_list):
    """Gemini API를 사용하여 텍스트 리스트의 감정을 분석합니다."""
    results = []

    # API 부하를 줄이기 위해 묶어서 질문하거나 루프를 돕니다.
    prompt_base = "다음 댓글의 감정을 '긍정', '부정', '중립' 중 하나로만 답변해줘: "

    for text in text_list:
        try:
            response = model.generate_content(prompt_base + text)
            sentiment = response.text.strip()
            # 응답값이 길 경우를 대비해 키워드만 추출
            if '긍정' in sentiment: sentiment = '긍정'
            elif '부정' in sentiment: sentiment = '부정'
            else: sentiment = '중립'
            results.append(sentiment)
        except Exception as e:
            results.append("오류")
            print(f"Error analyzing: {e}")

    return results

def visualize_results(df):
    """분석 결과를 시각화합니다."""
    plt.rc('font', family='NanumBarunGothic') # 윈도우 한글 깨짐 방지
    plt.rcParams['axes.unicode_minus'] = False

    plt.figure(figsize=(10, 6))
    sns.countplot(x='감정', data=df, palette='viridis', order=['긍정', '중립', '부정'])
    plt.title('SNS 댓글 감정 분석 결과')
    plt.xlabel('감정 상태')
    plt.ylabel('댓글 수')
    plt.show()

# 3. 메인 실행 흐름
def main():
    url = input("분석할 SNS 주소를 입력하세요: ")
    print(f"{url}에서 데이터를 수집 중입니다... (데모용 샘플 데이터 사용)")

    # [참고] 실제 크롤링 로직은 사이트별(유튜브/인스타)로 API나 셀레니움 라이브러리가 추가로 필요합니다.
    # 여기서는 분석 흐름을 보여주기 위해 샘플 데이터를 생성합니다.
    sample_comments = [
        "와 진짜 너무 유익해요! 감사합니다.",
        "이건 좀 아닌 것 같은데... 실망입니다.",
        "그냥 평범하네요. 볼만해요.",
        "역대급 영상입니다! 최고예요!",
        "시간 아까워요. 별로입니다.",
        "내용이 좀 어렵긴 한데 괜찮네요."
    ]

    # 감정 분석 수행
    print("Gemini AI를 통해 감정을 분석하고 있습니다...")
    sentiments = analyze_sentiment_with_gemini(sample_comments)

    # 데이터프레임 생성
    df = pd.DataFrame({
        '댓글': sample_comments,
        '감정': sentiments
    })

    print("\n[분석 결과 데이터]")
    print(df)

    # 시각화
    visualize_results(df)

if __name__ == "__main__":
    main()

!pip install google-api-python-client google-generativeai pandas matplotlib seaborn playwright
!playwright install chromium

import os
import re
import asyncio
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import google.generativeai as genai
from googleapiclient.discovery import build
from playwright.sync_api import sync_playwright
import time


# ==========================================
# 설정 영역 (본인의 API 키를 입력하세요)
# ==========================================
GOOGLE_AI_STUDIO_KEY = "AIzaSyBEmAHr7r1i2mt8yu6qjp3P79ErIfQrIfw"
YOUTUBE_API_KEY = "AIzaSyC_RJ6D_3TX-3GNeKpxdarBfOgcNFuR47k"

genai.configure(api_key=GOOGLE_AI_STUDIO_KEY)
gemini_model = genai.GenerativeModel('gemini-2.5-flash')

# ==========================================
# 1. 유튜브 댓글 수집 함수
# ==========================================
def get_youtube_comments(url):
    video_id_match = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11}).*", url)
    if not video_id_match:
        print("유효한 유튜브 URL이 아닙니다.")
        return []

    video_id = video_id_match.group(1)
    youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)

    try:
        request = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            maxResults=50  # 분석할 댓글 수
        )
        response = request.execute()
        comments = [item['snippet']['topLevelComment']['snippet']['textDisplay'] for item in response['items']]
        return comments
    except Exception as e:
        print(f"유튜브 데이터 수집 중 오류: {e}")
        return []

# ==========================================
# 2. 인스타그램 댓글 수집 함수 (Playwright 사용)
# ==========================================
def get_instagram_comments(url):
    comments = []
    with sync_playwright() as p:
        # 인스타그램은 로그인이 필요할 수 있으므로, 브라우저를 띄워 수동 로그인이 필요할 수 있습니다.
        browser = p.chromium.launch(headless=True) # 창을 보고 싶다면 False
        page = browser.new_page()
        try:
            page.goto(url)
            page.wait_for_timeout(5000) # 로딩 대기
            # 댓글 요소 선택 (인스타그램 클래스명은 자주 변경되므로 주의 필요)
            comment_elements = page.query_selector_all('ul span._ap3a')
            for el in comment_elements[:50]:
                comments.append(el.inner_text())
        except Exception as e:
            print(f"인스타그램 데이터 수집 중 오류: {e}")
        browser.close()
    return comments

# ==========================================
# 3. Gemini 감정 분석 함수
# ==========================================
def analyze_sentiments(comments):
    if not comments: return []

    results = []
    # 50개를 10개씩 5번만 호출하도록 설정 (API 할당량 소모를 1/10로 줄임)
    batch_size = 10

    print(f"총 {len(comments)}개의 댓글 분석 시작 (안정적인 분석을 위해 대기 시간이 포함됩니다)...")

    for i in range(0, len(comments), batch_size):
        batch = comments[i:i + batch_size]

        # 10개를 한 번에 분석하도록 요청하는 프롬프트
        prompt = (
            "너는 감정 분석 전문가야. 다음 SNS 댓글 리스트를 읽고 각 댓글의 감정을 '긍정', '부정', '중립' 중 하나로만 분류해줘. "
            "응답은 반드시 각 결과 사이에 콤마(,)를 사용해서 한 줄로 나열해줘. "
            "예시: 긍정, 부정, 중립, 긍정...\n\n"
        )
        for j, text in enumerate(batch):
            prompt += f"{j+1}. {text}\n"

        try:
            # API 호출
            response = gemini_model.generate_content(prompt)
            # 결과 텍스트 파싱
            batch_results = [res.strip() for res in response.text.split(',')]

            # 응답값이 '긍정', '부정', '중립' 형태인지 다시 한번 정제
            cleaned_results = []
            for res in batch_results:
                if '긍정' in res: cleaned_results.append('긍정')
                elif '부정' in res: cleaned_results.append('부정')
                else: cleaned_results.append('중립')

            results.extend(cleaned_results)
            print(f"[{min(i + batch_size, len(comments))}/{len(comments)}] 분석 완료...")

            # ★ 핵심: 무료 API 할당량을 위해 5초간 강제 휴식
            time.sleep(5)

        except Exception as e:
            print(f"오류 발생 ({e}), 잠시 대기 후 다음 단계로 이동합니다.")
            results.extend(['분석실패'] * len(batch))
            time.sleep(10) # 오류 발생 시 더 길게 휴식

    return results[:len(comments)]

def visualize_data(df):
    # 한글 깨짐 방지 (윈도우 기준, 맥은 AppleGothic)
    plt.rc('font', family='NanumBarunGothic')
    plt.figure(figsize=(10, 6))

    # FutureWarning 방지를 위해 x를 hue로 지정하고 legend=False 추가
    sns.countplot(data=df, x='감정', order=['긍정', '중립', '부정'],
                  hue='감정', palette='pastel', legend=False)

    plt.title("SNS 댓글 공감도 분석 결과")
    plt.xlabel("감정 분류")
    plt.ylabel("댓글 수")
    plt.show()

# ==========================================
# 메인 실행 로직
# ==========================================
def main():
    url = input("분석할 유튜브 또는 인스타그램 주소를 입력하세요: ")

    if "youtube.com" in url or "youtu.be" in url:
        comments = get_youtube_comments(url)
    elif "instagram.com" in url:
        print("인스타그램 수집을 시작합니다. (로그인 세션에 따라 제한될 수 있습니다)")
        comments = get_instagram_comments(url)
    else:
        print("지원하지 않는 사이트입니다.")
        return

    if not comments:
        print("댓글을 수집하지 못했습니다.")
        return

    # 분석 및 데이터화
    sentiments = analyze_sentiments(comments)
    df = pd.DataFrame({'댓글': comments[:len(sentiments)], '감정': sentiments})

    print("\n--- 분석 요약 ---")
    print(df['감정'].value_counts())

    visualize_data(df)

if __name__ == "__main__":
    main()
