import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import urllib.parse

# ---------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="ì„¸ê³„ì‚¬ ì¸ë¬¼ ê²€ìƒ‰ê¸°",
    page_icon="ğŸŒ",
    layout="wide"
)

st.title("ğŸŒ ì„¸ê³„ì‚¬ ì¸ë¬¼ ë°±ê³¼ì‚¬ì „")
st.markdown("---")
st.info("ğŸ’¡ ìœ„í‚¤ë°±ê³¼(Wikipedia)ì˜ ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ Geminiê°€ ìš”ì•½Â·ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.")

# ---------------------------------------------------------
# 2. API í‚¤ ì„¤ì • (ë©”ì¸ app.pyì™€ ì—°ë™)
# ---------------------------------------------------------
try:
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
    else:
        api_key = st.sidebar.text_input("Gemini API Key", type="password")
    
    if api_key:
        genai.configure(api_key=api_key)
        # ì†ë„ê°€ ë¹ ë¥¸ Flash ëª¨ë¸ ì‚¬ìš© ê¶Œì¥
        model = genai.GenerativeModel('gemini-2.5-flash')
    else:
        st.warning("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# ---------------------------------------------------------
# 3. ìœ„í‚¤ë°±ê³¼ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
# ---------------------------------------------------------
@st.cache_data(ttl=3600)
def get_wiki_data(name):
    """
    ìœ„í‚¤ë°±ê³¼ì—ì„œ í…ìŠ¤íŠ¸ì™€ ëŒ€í‘œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    # URL ì¸ì½”ë”© (í•œê¸€ -> %EB%82...)
    encoded_name = urllib.parse.quote(name)
    url = f"https://ko.wikipedia.org/wiki/{encoded_name}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        response = requests.get(url, headers=headers, timeout=5)
        
        # 404 ë“± ì—ëŸ¬ ì²´í¬
        if response.status_code != 200:
            return None, None

        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 1. ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        content_div = soup.find('div', {'class': 'mw-parser-output'})
        text_data = ""
        if content_div:
            # ëª¨ë“  p íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘
            paragraphs = content_div.find_all('p')
            for p in paragraphs:
                text_data += p.get_text() + "\n"
            text_data = text_data[:6000] # ë„ˆë¬´ ê¸¸ë©´ í† í° ì œí•œ, ì ì ˆíˆ ìë¦„

        # 2. ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ (ì •ë³´ìƒì infobox ë‚´ë¶€ì˜ ì´ë¯¸ì§€ ì‹œë„)
        image_url = None
        infobox = soup.select_one('.infobox img') # ì •ë³´ìƒì ë‚´ ì´ë¯¸ì§€
        if not infobox:
            infobox = soup.select_one('.mw-parser-output .thumb img') # ì¸ë„¤ì¼ ì´ë¯¸ì§€

        if infobox:
            img_src = infobox.get('src')
            if img_src.startswith('//'):
                image_url = "https:" + img_src
            elif img_src.startswith('http'):
                image_url = img_src

        return text_data, image_url

    except Exception as e:
        return None, None

# ---------------------------------------------------------
# 4. AI ë¶„ì„ í•¨ìˆ˜
# ---------------------------------------------------------
def analyze_wiki_text(name, wiki_text):
    """Geminië¥¼ ì´ìš©í•œ ìš”ì•½ ë° ë¶„ì„"""
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì„¸ê³„ì‚¬ ì „ë¬¸ ì—­ì‚¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. 
    ì•„ë˜ [ìœ„í‚¤ë°±ê³¼ í…ìŠ¤íŠ¸]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ë¬¼ '{name}'ì— ëŒ€í•´ í•™ìƒë“¤ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì •ë¦¬í•´ì£¼ì„¸ìš”.

    [ìœ„í‚¤ë°±ê³¼ í…ìŠ¤íŠ¸]
    {wiki_text}

    [ì¶œë ¥ í˜•ì‹]
    ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´(Markdown)ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    
    1. **í•œ ì¤„ ì†Œê°œ**: (ì´ ì¸ë¬¼ì„ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” í•œ ë¬¸ì¥)
    2. **ê¸°ë³¸ ì •ë³´**:
       - **ì¶œìƒ-ì‚¬ë§**: (ì—°ë„)
       - **êµ­ì /ì‹œëŒ€**: (êµ­ê°€ ë° í™œë™ ì‹œê¸°)
       - **ì§ì—…**: (í™©ì œ, ì¥êµ°, ì˜ˆìˆ ê°€ ë“±)
    3. **ì£¼ìš” ì—…ì  (3ê°€ì§€)**:
       - (ì—…ì  1)
       - (ì—…ì  2)
       - (ì—…ì  3)
    4. **ì—­ì‚¬ì  í‰ê°€**: (ê¸ì •ì  í‰ê°€ì™€ ë¶€ì •ì  í‰ê°€ í˜¹ì€ ì˜ì˜ë¥¼ ê°„ë‹¨íˆ ì„œìˆ )
    5. **í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤**: (êµê³¼ì„œì— ì˜ ì•ˆ ë‚˜ì˜¤ëŠ” ì¬ë¯¸ìˆëŠ” ì¼í™” 1ê°€ì§€, í…ìŠ¤íŠ¸ì— ì—†ë‹¤ë©´ ìƒëµ ê°€ëŠ¥)
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ---------------------------------------------------------
# 5. UI êµ¬ì„±
# ---------------------------------------------------------
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### ğŸ” ì¸ë¬¼ ê²€ìƒ‰")
    target_name = st.text_input("ì¸ë¬¼ ì´ë¦„ (ì˜ˆ: ë‚˜í´ë ˆì˜¹, ì¹­ê¸°ì¦ˆ ì¹¸, ê°„ë””)", placeholder="ì •í™•í•œ ëª…ì¹­ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    st.info("""
    **ğŸ’¡ ê²€ìƒ‰ íŒ**
    - 'ì´ìˆœì‹ ' (O)
    - 'ë‚˜í´ë ˆì˜¹ 1ì„¸' (O)
    - ë³„ëª…ë³´ë‹¤ëŠ” **ê³µì‹ ëª…ì¹­**ì´ ì •í™•í•©ë‹ˆë‹¤.
    """)
    
    search_btn = st.button("ê²€ìƒ‰ ë° ë¶„ì„", type="primary", use_container_width=True)

with col2:
    if search_btn and target_name:
        st.divider()
        
        # 1. ë°ì´í„° ìˆ˜ì§‘
        with st.status(f"ğŸŒ ìœ„í‚¤ë°±ê³¼ì—ì„œ '{target_name}' ì°¾ëŠ” ì¤‘...", expanded=True) as status:
            wiki_text, img_url = get_wiki_data(target_name)
            
            if wiki_text:
                status.update(label="âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.", state="complete", expanded=False)
            else:
                status.update(label="âŒ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", state="error")
                st.error("ìœ„í‚¤ë°±ê³¼ì— í•´ë‹¹ ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ì´ë¦„ì´ ì •í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.stop()
        
        # 2. ê²°ê³¼ ì¶œë ¥ ë ˆì´ì•„ì›ƒ
        # ìƒë‹¨: ì´ë¯¸ì§€ì™€ ê¸°ë³¸ ìš”ì•½ ë³‘ë ¬ ë°°ì¹˜
        
        st.subheader(f"ğŸ“œ {target_name} ë¶„ì„ ê²°ê³¼")
        
        result_container = st.container()
        
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if img_url:
            col_img, col_desc = st.columns([1, 2])
            with col_img:
                st.image(img_url, caption=target_name, use_column_width=True)
            with col_desc:
                with st.spinner("ğŸ¤– Geminiê°€ ì—´ì‹¬íˆ ìš”ì•½í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    result_text = analyze_wiki_text(target_name, wiki_text)
                    st.markdown(result_text)
        else:
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œ ë„“ê²Œ í‘œì‹œ
            with st.spinner("ğŸ¤– Geminiê°€ ì—´ì‹¬íˆ ìš”ì•½í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                result_text = analyze_wiki_text(target_name, wiki_text)
                st.markdown(result_text)

        # 3. ì›ë³¸ í…ìŠ¤íŠ¸ í™•ì¸ (ì ‘ê¸°/í¼ì¹˜ê¸°)
        with st.expander("ğŸ“š ìœ„í‚¤ë°±ê³¼ ì›ë¬¸ í…ìŠ¤íŠ¸ ë³´ê¸° (ì¼ë¶€)"):
            st.text(wiki_text[:1000] + "\n... (ì¤‘ëµ) ...")
            st.caption(f"ì¶œì²˜: ìœ„í‚¤ë°±ê³¼ ({target_name})")

    elif search_btn and not target_name:
        st.error("ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
