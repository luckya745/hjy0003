# -*- coding: utf-8 -*-
"""ë³‘ìí˜¸ë€ ë‹¹ì‹œ ì£¼ì „ë¡ ê³¼ ì£¼í™”ë¡  ë¶„ë¥˜(ê°œë°œì¤‘).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nhF71TrL2bjESiCJIS_kWDVuSEznn7sn
"""

pip install google-generativeai requests beautifulsoup4

import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import streamlit as st  # ì´ ì¤„ì´ ì—†ìœ¼ë©´ ë§¨ ìœ„ì— ì¶”ê°€í•´ì£¼ì„¸ìš”!

# ì´ì œ ì‹¤ì œ í‚¤ ëŒ€ì‹  'ë¹„ë°€ ê¸ˆê³ 'ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤
GOOGLE_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)


# ê²½ê³  ë©”ì‹œì§€ê°€ ë¶ˆí¸í•˜ë‹¤ë©´ ìµœì‹  íŒ¨í‚¤ì§€(google.genai)ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ í•„ìš”í•˜ì§€ë§Œ,
# í˜„ì¬ ì½”ë“œ ì‘ë™ì„ ìœ„í•´ ê¸°ì¡´ ë°©ì‹ì„ ìœ ì§€í•˜ë˜ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
try:
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('gemini-flash-2.5')
except Exception as e:
    print(f"âš ï¸ Gemini ì„¤ì • ì˜¤ë¥˜: {e}")

# ==========================================
# 2. ì›¹ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (ìˆ˜ì •ë¨: í—¤ë” ì¶”ê°€ ë° HTTPS ì ìš©)
# ==========================================
def scrape_historical_records(person_name):
    """
    ì¡°ì„ ì™•ì¡°ì‹¤ë¡ ì‚¬ì´íŠ¸ì—ì„œ ì¸ë¬¼ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬
    ë´‡ ì°¨ë‹¨ì„ ìš°íšŒí•˜ê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    print(f"ğŸ” '{person_name}'ì— ëŒ€í•œ ê¸°ë¡ì„ í•œêµ­ì‚¬ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ ì¤‘...")

    # [ìˆ˜ì • 1] http -> https (ë³´ì•ˆ ì—°ê²° ì‚¬ìš©)
    base_url = "https://sillok.history.go.kr/search/searchResultList.do"

    # [ìˆ˜ì • 2] ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ 'User-Agent' í—¤ë” ì¶”ê°€ (ë¸Œë¼ìš°ì €ì¸ ì²™í•˜ê¸°)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    # [ìˆ˜ì • 3] ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì ê²€
    params = {
        'searchKeyword': person_name, # ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ì¶° íŒŒë¼ë¯¸í„°ëª… ë³€ê²½ ê°€ëŠ¥ì„± ëŒ€ë¹„
        'rowPerPage': 5               # ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ 5ê±´ìœ¼ë¡œ ì¡°ì •
    }

    try:
        # timeout ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ë¡œë”© ë°©ì§€
        response = requests.get(base_url, headers=headers, params=params, timeout=10)

        # 400/500 ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        results = []
        # ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¥¸ ì„ íƒì (ì‹¤ì œ ì‚¬ì´íŠ¸ HTML êµ¬ì¡°ì— ì˜ì¡´í•¨)
        articles = soup.select("ul.result_list > li")

        if not articles:
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
            print(f"   ğŸ‘‰ '{person_name}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        for i, article in enumerate(articles):
            if i >= 3: break # ë„ˆë¬´ ë§ì€ ë°ì´í„°ëŠ” í† í° ë‚­ë¹„ì´ë¯€ë¡œ ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©

            title_tag = article.select_one("dl > dt > a")
            if title_tag:
                title = title_tag.get_text(strip=True)
                desc_tag = article.select_one("dl > dd.desc")
                desc = desc_tag.get_text(strip=True) if desc_tag else ""
                results.append(f"ê¸°ì‚¬: {title}\në‚´ìš©: {desc}")

        full_text = "\n---\n".join(results)
        return full_text

    except requests.exceptions.HTTPError as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ê±°ë¶€ (HTTP Error): {e}")
        return None
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        return None

# ==========================================
# 3. AI ë¶„ì„ ë° ë¶„ë¥˜ í•¨ìˆ˜
# ==========================================
def classify_figure(person_name, historical_text):
    if not historical_text:
        return "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    print(f"ğŸ¤– Geminiê°€ '{person_name}'ì˜ ì„±í–¥ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n")

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì—ì„œ '{person_name}'ì„ ê²€ìƒ‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
    ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ ì¸ë¬¼ì´ 'ë³‘ìí˜¸ë€(1636)' ë‹¹ì‹œ ì–´ë–¤ ì…ì¥ì´ì—ˆëŠ”ì§€ íŒë³„í•˜ì„¸ìš”.

    [ë¶„ì„ í…ìŠ¤íŠ¸]
    {historical_text}

    [í•„ìˆ˜ ë‹µë³€ ì–‘ì‹]
    1. ë¶„ë¥˜: [ì£¼ì „ë¡ ì (ì²™í™”íŒŒ) / ì£¼í™”ë¡ ì (ì£¼í™”íŒŒ) / íŒë‹¨ ë¶ˆê°€]
    2. ì´ìœ : (í•™ìƒë“¤ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ 2ë¬¸ì¥ ë‚´ì™¸ë¡œ ì„¤ëª…)
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ API ë¶„ì„ ì˜¤ë¥˜: {e}"

# ==========================================
# 4. ì‹¤í–‰ë¶€
# ==========================================
if __name__ == "__main__":
    while True:
        target_name = input("\nì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: q): ").strip()
        if target_name.lower() == 'q': break
        if not target_name: continue

        data = scrape_historical_records(target_name)

        if data:
            analysis = classify_figure(target_name, data)
            print("\n--- ë¶„ì„ ê²°ê³¼ ---")
            print(analysis)
        else:
            print(f"'{target_name}'ì— ëŒ€í•œ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

import google.generativeai as genai
import requests
from bs4 import BeautifulSoup

# ==========================================
# 1. API í‚¤ ì„¤ì •
# ==========================================
API_KEY = "AIzaSyBEmAHr7r1i2mt8yu6qjp3P79ErIfQrIfw"  # API í‚¤ë¥¼ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.

try:
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('gemini-pro')
except Exception as e:
    print(f"âš ï¸ Gemini ì„¤ì • ì˜¤ë¥˜: {e}")

# ==========================================
# 2. ì›¹ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (ìµœì¢… ìˆ˜ì •ë²„ì „)
# ==========================================
def scrape_historical_records(person_name):
    print(f"ğŸ” '{person_name}' ê²€ìƒ‰ ì¤‘... (í•œêµ­ì‚¬ë°ì´í„°ë² ì´ìŠ¤)")

    # 1. URL: HTTP ì‚¬ìš© (HTTPS ê°•ì œ ì‹œ ì˜¤ë¥˜ ê°€ëŠ¥ì„± ë°°ì œ)
    base_url = "http://sillok.history.go.kr/search/searchResultList.do"

    # 2. í—¤ë”: ë¸Œë¼ìš°ì €ì¸ ì²™ ìœ„ì¥ (400 ì—ëŸ¬ ë°©ì§€ í•µì‹¬)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Referer': 'http://sillok.history.go.kr/'
    }

    # 3. íŒŒë¼ë¯¸í„°: 'keyword'ê°€ ì •í™•í•œ ë³€ìˆ˜ëª…ì…ë‹ˆë‹¤ (404 ì—ëŸ¬ ë°©ì§€ í•µì‹¬)
    params = {
        'keyword': person_name,
        'rowPerPage': 5
    }

    try:
        response = requests.get(base_url, headers=headers, params=params, timeout=10)
        response.raise_for_status() # 400, 404, 500 ë“± ì—ëŸ¬ ë°œìƒ ì‹œ ì¦‰ì‹œ ì•Œë¦¼

        soup = BeautifulSoup(response.text, 'html.parser')

        results = []
        articles = soup.select("ul.result_list > li")

        if not articles:
            print(f"   ğŸ‘‰ '{person_name}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ìƒìœ„ 3ê°œ ê¸°ì‚¬ë§Œ ìš”ì•½í•´ì„œ ê°€ì ¸ì˜¤ê¸°
        for i, article in enumerate(articles):
            if i >= 3: break

            title_tag = article.select_one("dl > dt > a")
            if title_tag:
                title = title_tag.get_text(strip=True)
                desc_tag = article.select_one("dl > dd.desc")
                desc = desc_tag.get_text(strip=True) if desc_tag else ""
                results.append(f"- ê¸°ì‚¬: {title}\n- ë‚´ìš©: {desc}")

        return "\n\n".join(results)

    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        return None

# ==========================================
# 3. AI ë¶„ì„ í•¨ìˆ˜
# ==========================================
def classify_figure(person_name, historical_text):
    # ìŠ¤í¬ë˜í•‘ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ Gemini ë‚´ì¥ ì§€ì‹ìœ¼ë¡œ ëŒ€ì²´ (ìˆ˜ì—… ëŠê¹€ ë°©ì§€)
    if not historical_text:
        print("âš ï¸ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨. Geminiì˜ ë‚´ì¥ ì§€ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        prompt = f"""
        ì¡°ì„ ì‹œëŒ€ ì¸ë¬¼ '{person_name}'ì´ ë³‘ìí˜¸ë€(1636) ë‹¹ì‹œ
        ì²­ë‚˜ë¼ì™€ ì‹¸ìš°ìëŠ” 'ì£¼ì „ë¡ (ì²™í™”íŒŒ)'ì´ì—ˆëŠ”ì§€, í™”ì¹œí•˜ìëŠ” 'ì£¼í™”ë¡ (ì£¼í™”íŒŒ)'ì´ì—ˆëŠ”ì§€ íŒë³„í•´ì¤˜.

        ë‹µë³€ í˜•ì‹:
        1. ë¶„ë¥˜: [ì£¼ì „ë¡ ì / ì£¼í™”ë¡ ì]
        2. ì´ìœ : í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
        """
    else:
        prompt = f"""
        ë‹¤ìŒì€ ì¡°ì„ ì™•ì¡°ì‹¤ë¡ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.
        ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{person_name}'ì´ ë³‘ìí˜¸ë€ ë‹¹ì‹œ ì–´ë–¤ ì…ì¥ì´ì—ˆëŠ”ì§€ íŒë³„í•˜ì‹œì˜¤.

        [ê²€ìƒ‰ ê²°ê³¼]
        {historical_text}

        ë‹µë³€ í˜•ì‹:
        1. ë¶„ë¥˜: [ì£¼ì „ë¡ ì / ì£¼í™”ë¡ ì]
        2. ì´ìœ : ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…
        """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ ë¶„ì„ ì˜¤ë¥˜: {e}"

# ==========================================
# 4. ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    while True:
        name = input("\nì¸ë¬¼ ì´ë¦„ ì…ë ¥ (ì¢…ë£Œ: q): ").strip()
        if name.lower() == 'q': break
        if not name: continue

        # ìŠ¤í¬ë˜í•‘ ì‹œë„
        data = scrape_historical_records(name)

        # ê²°ê³¼ ì¶œë ¥
        print("-" * 30)
        print(classify_figure(name, data))
        print("-" * 30)
