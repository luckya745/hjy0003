# -*- coding: utf-8 -*-
"""ë³‘ìí˜¸ë€ë‹¹ì‹œ ì£¼ì „ë¡ ìì™€ ì£¼í™”ë¡ ì ë¶„ë¥˜ëª¨ë¸.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15YQC_WP-r5f5NAQqScM5hlEOgJ90gO7k
"""

import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import textwrap
import streamlit as st  # ì´ ì¤„ì´ ì—†ìœ¼ë©´ ë§¨ ìœ„ì— ì¶”ê°€í•´ì£¼ì„¸ìš”!

# ì´ì œ ì‹¤ì œ í‚¤ ëŒ€ì‹  'ë¹„ë°€ ê¸ˆê³ 'ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤
GOOGLE_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel('gemini-1.5-flash') # ì†ë„ì™€ íš¨ìœ¨ì„±ì„ ìœ„í•´ Flash ëª¨ë¸ ì‚¬ìš©

# ==========================================
# 2. ì›¹ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (Web Scraper)
# ==========================================
def scrape_history_net(person_name):
    """
    ìš°ë¦¬ì—­ì‚¬ë„·(contents.history.go.kr)ì—ì„œ ì¸ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    base_url = "https://contents.history.go.kr/front/search/totalSearch.do"

    # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
    params = {
        'searchText': person_name,
        'searchType': 'all'
    }

    # ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ í—¤ë” ì„¤ì •
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        print(f"ğŸŒ '{person_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš°ë¦¬ì—­ì‚¬ë„·ì—ì„œ ìˆ˜ì§‘ ì¤‘...")
        response = requests.get(base_url, params=params, headers=headers)
        response.raise_for_status() # ì—ëŸ¬ ì²´í¬

        soup = BeautifulSoup(response.text, 'html.parser')

        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ classëª…ì€ ë³€ë™ë  ìˆ˜ ìˆìŒ)
        # ì¼ë°˜ì ì¸ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì˜ ìš”ì•½ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        results = []

        # 'search_list' í´ë˜ìŠ¤ ë‚´ì˜ í…ìŠ¤íŠ¸ë“¤ì„ ìˆ˜ì§‘ (ì˜ˆì‹œ êµ¬ì¡°)
        search_items = soup.select('.search_list li .conts')

        for item in search_items[:3]: # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì°¸ì¡°
            text = item.get_text(strip=True)
            results.append(text)

        if not results:
            print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìƒì„¸ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (LLM ì§€ì‹ì— ì˜ì¡´í•©ë‹ˆë‹¤)")
            return None

        combined_text = "\n".join(results)
        print(f"   âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(combined_text)}ì)")
        return combined_text

    except Exception as e:
        print(f"   âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ==========================================
# 3. AI ë¶„ë¥˜ ëª¨ë¸ í•¨ìˆ˜ (AI Classifier)
# ==========================================
def classify_political_stance(name, context_text):
    """
    ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Geminiê°€ ì£¼ì „ë¡ /ì£¼í™”ë¡ ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """

    # ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´(ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ) LLMì˜ ê¸°ë³¸ ì§€ì‹ì„ ì‚¬ìš©í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¡°ì •
    context_prompt = ""
    if context_text:
        context_prompt = f"ì°¸ê³ í•  ì—­ì‚¬ì  ì‚¬ë£Œ ë‚´ìš©:\n{context_text}\n\n"

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ [ì…ë ¥ëœ ì¸ë¬¼]ì´ ë³‘ìí˜¸ë€(1636ë…„) ë‹¹ì‹œ ì–´ë–¤ ì •ì¹˜ì  ì…ì¥ì„ ì·¨í–ˆëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

    [ì…ë ¥ëœ ì¸ë¬¼]: {name}
    {context_prompt}

    ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:
    1. ê²°ë¡ : ì´ ì‚¬ëŒì´ 'ì£¼ì „ë¡ ì(ì²™í™”íŒŒ)'ì¸ì§€ 'ì£¼í™”ë¡ ì(ì£¼í™”íŒŒ)'ì¸ì§€, í˜¹ì€ 'ì¤‘ë¦½/ê¸°íƒ€'ì¸ì§€ ëª…í™•íˆ ë¶„ë¥˜í•˜ì„¸ìš”.
    2. ê·¼ê±°: ìœ„ ë¶„ë¥˜ì˜ ì´ìœ ë¥¼ ì—­ì‚¬ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    3. ë§Œì•½ ë³‘ìí˜¸ë€ê³¼ ê´€ë ¨ì´ ì—†ëŠ” ì¸ë¬¼ì´ë¼ë©´ "ë³‘ìí˜¸ë€ê³¼ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ê±°ë‚˜ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ==========================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Main)
# ==========================================
def main():
    print("=== ë³‘ìí˜¸ë€ ì¸ë¬¼ ì„±í–¥ ë¶„ë¥˜ê¸° (ìš°ë¦¬ì—­ì‚¬ë„· + Google Gemini) ===")
    print("ì˜ˆì‹œ: ê¹€ìƒí—Œ, ìµœëª…ê¸¸, í™ìµí•œ, ì¸ì¡° ë“±")

    while True:
        target_person = input("\nğŸ” ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'q' ì…ë ¥): ").strip()

        if target_person.lower() == 'q':
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not target_person:
            continue

        # 1ë‹¨ê³„: ì›¹ ìŠ¤í¬ë˜í•‘
        scraped_data = scrape_history_net(target_person)

        # 2ë‹¨ê³„: AI ë¶„ë¥˜
        print("ğŸ¤– AIê°€ ì—­ì‚¬ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        result = classify_political_stance(target_person, scraped_data)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*40)
        print(f"[{target_person}] ë¶„ë¥˜ ê²°ê³¼")
        print("="*40)
        print(result)
        print("="*40)

if __name__ == "__main__":
    main()

pip install --upgrade google-generativeai requests beautifulsoup4

import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import urllib3

# SSL ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸° (ê¹”ë”í•œ ì¶œë ¥ì„ ìœ„í•´)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================

# ì´ì œ ì‹¤ì œ í‚¤ ëŒ€ì‹  'ë¹„ë°€ ê¸ˆê³ 'ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤
GOOGLE_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)

# Gemini ëª¨ë¸ ì„¤ì •
try:
    genai.configure(api_key=GOOGLE_API_KEY)
    # ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œëŠ” flash ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥. ë§Œì•½ 404 ì—ëŸ¬ê°€ ê³„ì†ë˜ë©´ 'gemini-pro'ë¡œ ë³€ê²½í•˜ì„¸ìš”.
    model = genai.GenerativeModel('gemini-2.5-flash')
except Exception as e:
    print(f"ëª¨ë¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ==========================================
# 2. ì›¹ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (Web Scraper) - ìˆ˜ì •ë¨
# ==========================================
def scrape_history_net(person_name):
    """
    ìš°ë¦¬ì—­ì‚¬ë„·ì—ì„œ ì¸ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (SSL ê²€ì¦ ë¬´ì‹œ ë° í—¤ë” ê°•í™”)
    """
    base_url = "https://contents.history.go.kr/front/search/totalSearch.do"

    params = {
        'searchText': person_name,
        'searchType': 'all'
    }

    # í—¤ë”ë¥¼ ë” ìƒì„¸í•˜ê²Œ ì„¤ì •í•˜ì—¬ ì°¨ë‹¨ ìš°íšŒ ì‹œë„
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://contents.history.go.kr/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
    }

    try:
        print(f"ğŸŒ '{person_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš°ë¦¬ì—­ì‚¬ë„·ì—ì„œ ì°¾ëŠ” ì¤‘...")

        # verify=False ì˜µì…˜ ì¶”ê°€ (SSL ì¸ì¦ì„œ ì˜¤ë¥˜ ë¬´ì‹œ)
        response = requests.get(base_url, params=params, headers=headers, verify=False, timeout=10)

        if response.status_code != 200:
            print(f"   âš ï¸ ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code}) -> AI ì§€ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return None

        soup = BeautifulSoup(response.text, 'html.parser')

        # ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        results = []
        search_items = soup.select('.search_list li .conts')

        for item in search_items[:3]:
            text = item.get_text(strip=True)
            results.append(text)

        if not results:
            print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ -> AI ì§€ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return None

        combined_text = "\n".join(results)
        print(f"   âœ… ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ ({len(combined_text)}ì)")
        return combined_text

    except Exception as e:
        # ì˜¤ë¥˜ê°€ ë‚˜ë„ ë©ˆì¶”ì§€ ì•Šê³  Noneì„ ë°˜í™˜í•˜ì—¬ AIê°€ ì²˜ë¦¬í•˜ê²Œ í•¨
        print(f"   âš ï¸ ìŠ¤í¬ë˜í•‘ ê±´ë„ˆëœ€ (ì‚¬ìœ : {e}) -> AI ì§€ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return None

# ==========================================
# 3. AI ë¶„ë¥˜ ëª¨ë¸ í•¨ìˆ˜
# ==========================================
def classify_political_stance(name, context_text):

    context_prompt = ""
    if context_text:
        context_prompt = f"ì°¸ê³ í•  ìš°ë¦¬ì—­ì‚¬ë„· ê²€ìƒ‰ ê²°ê³¼:\n{context_text}\n\n"

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ [ì…ë ¥ëœ ì¸ë¬¼]ì´ ë³‘ìí˜¸ë€(1636ë…„) ë‹¹ì‹œ ì–´ë–¤ ì •ì¹˜ì  ì…ì¥ì„ ì·¨í–ˆëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

    [ì…ë ¥ëœ ì¸ë¬¼]: {name}
    {context_prompt}

    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
    1. **ë¶„ë¥˜**: [ì£¼ì „ë¡ (ì²™í™”íŒŒ) / ì£¼í™”ë¡ (ì£¼í™”íŒŒ) / ì¤‘ë¦½ / ê´€ë ¨ ì—†ìŒ] ì¤‘ íƒ 1
    2. **í•µì‹¬ ì´ìœ **: ì—­ì‚¬ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ 2ë¬¸ì¥ ë‚´ì™¸ë¡œ ìš”ì•½
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n(íŒ: google-generativeai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•´ë³´ì„¸ìš”)"

# ==========================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main():
    print("=== ë³‘ìí˜¸ë€ ì¸ë¬¼ ì„±í–¥ ë¶„ë¥˜ê¸° (ìˆ˜ì •ë²„ì „) ===")

    while True:
        target_person = input("\nğŸ” ì¸ë¬¼ ì´ë¦„ ì…ë ¥ (ì¢…ë£Œ: q): ").strip()

        if target_person.lower() == 'q':
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not target_person:
            continue

        # 1ë‹¨ê³„: ìŠ¤í¬ë˜í•‘ (ì‹¤íŒ¨í•´ë„ í”„ë¡œê·¸ë¨ ì£½ì§€ ì•ŠìŒ)
        scraped_data = scrape_history_net(target_person)

        # 2ë‹¨ê³„: AI ë¶„ë¥˜
        print("ğŸ¤– AI ë¶„ì„ ì¤‘...")
        result = classify_political_stance(target_person, scraped_data)

        print("-" * 50)
        print(result)
        print("-" * 50)

if __name__ == "__main__":
    main()
