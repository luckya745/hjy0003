# -*- coding: utf-8 -*-
"""ë…¸ì…˜ ì›¹ì‚¬ì´íŠ¸ ì›¹ìŠ¤í¬ë˜í•‘ í›„ í…ìŠ¤íŠ¸ë§ˆì´ë‹.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SPCr2yzQ4wiuk0RSchwb6ePIHQXf0T1R
"""

pip install pandas matplotlib wordcloud scikit-learn nltk konlpy google-generativeai requests

import requests
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from konlpy.tag import Okt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
import google.generativeai as genai
from collections import Counter

# 1. í™˜ê²½ ì„¤ì •
NOTION_TOKEN = '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'
DATABASE_ID = '2d19e99c537880898d81f3b5f9c7b673'
import streamlit as st  # ì´ ì¤„ì´ ì—†ìœ¼ë©´ ë§¨ ìœ„ì— ì¶”ê°€í•´ì£¼ì„¸ìš”!

# ì´ì œ ì‹¤ì œ í‚¤ ëŒ€ì‹  'ë¹„ë°€ ê¸ˆê³ 'ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤
GOOGLE_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)

# 1. Google AI Studio ì„¤ì •
model = genai.GenerativeModel('gemini-2.5-flash')

def get_notion_data(token, db_id):
    url = f"https://api.notion.com/v1/databases/{db_id}/query"
    headers = {
        "Authorization": f"Bearer {token}",
        "Notion-Version": "2022-06-28",
        "Content-Type": "application/json"
    }

    texts = []
    has_more = True
    next_cursor = None

    while has_more:
        payload = {"start_cursor": next_cursor} if next_cursor else {}
        response = requests.post(url, json=payload, headers=headers)

        if response.status_code != 200:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            break

        data = response.json()

        for row in data.get('results', []):
            properties = row.get('properties', {})
            for prop in properties.values():
                # ëª¨ë“  í…ìŠ¤íŠ¸ ê¸°ë°˜ ì†ì„±(ì œëª©, ë¦¬ì¹˜í…ìŠ¤íŠ¸, ì„ íƒí•­ëª© ë“±)ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if prop['type'] == 'title' and prop['title']:
                    texts.append(prop['title'][0]['plain_text'])
                elif prop['type'] == 'rich_text' and prop['rich_text']:
                    texts.append(prop['rich_text'][0]['plain_text'])
                elif prop['type'] == 'select' and prop['select']:
                    texts.append(prop['select']['name'])
                elif prop['type'] == 'multi_select' and prop['multi_select']:
                    for item in prop['multi_select']:
                        texts.append(item['name'])

        has_more = data.get('has_more', False)
        next_cursor = data.get('next_cursor')

    print(f"âœ… ì´ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    return texts

def preprocess_korean(texts):
    okt = Okt()
    all_nouns = []
    # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ ì¥ì¹˜
    if not texts:
        return []
    for text in texts:
        nouns = okt.nouns(text)
        all_nouns.extend([n for n in nouns if len(n) > 1])
    return all_nouns

#ë…¸íŠ¸ë¶ì´ ì½”ë©ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ ì²´í¬í•©ë‹ˆë‹¤.

import sys
if 'google.colab' in sys.modules:
  !echo 'debconf debconf/frontend select Noniteractive' | \
  debconf-set-selections

  # ë‚˜ëˆ” í°íŠ¸ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
  !sudo apt-get -qq -y install fonts-nanum
  import matplotlib.font_manager as fm
  font_files = fm.findSystemFonts(fontpaths=['/usr/share/fonts/truetype/nanum'])
  for fpath in font_files:
    fm.fontManager.addfont(fpath)

import matplotlib.pyplot as plt
plt.rc('font', family='NanumBarunGothic')
plt.rcParams['figure.dpi']=100

import platform
import matplotlib.pyplot as plt
import pandas as pd
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# 1. í°íŠ¸ ê°•ì œ ì„¤ì • í•¨ìˆ˜
def get_reliable_font():
    sys_name = platform.system()
    if sys_name == "Windows":
        return "malgun.ttf"
    elif sys_name == "Darwin":
        return "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
    else:
        # Colab/Linux í™˜ê²½ì—ì„œ í°íŠ¸ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë‚˜ëˆ”í°íŠ¸ ì„¤ì¹˜ í™•ì¸
        import os
        colab_font = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        if os.path.exists(colab_font):
            return colab_font
        else:
            print("ğŸ’¡ Colab í™˜ê²½: í°íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ í›„ ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            return None

# 2. í†µí•© ë¶„ì„ ì‹¤í–‰ (ì´ ë¶€ë¶„ìœ¼ë¡œ ê¸°ì¡´ ì‹¤í–‰ë¶€ë¥¼ ëŒ€ì²´í•˜ì„¸ìš”)
try:
    print("ğŸš€ ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    raw_texts = get_notion_data(NOTION_TOKEN, DATABASE_ID)

    if not raw_texts:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë…¸ì…˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        nouns = preprocess_korean(raw_texts)
        count = dict(Counter(nouns).most_common(100)) # ë¹ˆë„ìˆ˜ ìƒìœ„ 100ê°œ

        # --- A. ì›Œë“œí´ë¼ìš°ë“œ ê°•ì œ ì¶œë ¥ ---
        print("ğŸ¨ ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™” ì¤‘...")
        font = get_reliable_font()

        # í°íŠ¸ê°€ ì—†ë”ë¼ë„ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹¤í–‰ë˜ë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”
        wc = WordCloud(
            font_path=font,
            background_color='white',
            width=1000,
            height=600,
            prefer_horizontal=0.9,
            colormap='coolwarm'
        ).generate_from_frequencies(count)

        plt.figure(figsize=(12, 7))
        plt.imshow(wc, interpolation='bilinear')
        plt.axis('off')
        plt.title("< Notion Content Analysis >", fontsize=20)
        plt.show()

        # --- B. í† í”½ ëª¨ë¸ë§ ê²°ê³¼ ì‹œê°í™” ---
        print("ğŸ§¬ í† í”½ ëª¨ë¸ë§ ë¶„ì„ ë° ê²°ê³¼ ì¶œë ¥...")
        n_topics = 3
        vectorizer = CountVectorizer(max_features=1000)
        data_vectorized = vectorizer.fit_transform(raw_texts)

        lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)
        lda.fit(data_vectorized)

        # í† í”½ë³„ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ ë° í‘œ ì‘ì„±
        feature_names = vectorizer.get_feature_names_out()
        topics_data = []

        for idx, topic in enumerate(lda.components_):
            top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]
            topics_data.append({"Topic": f"ì£¼ì œ {idx+1}", "Keywords": ", ".join(top_words)})

        df_topics = pd.DataFrame(topics_data)
        print("\n[í† í”½ ëª¨ë¸ë§ ê²°ê³¼ ìš”ì•½]")
        print(df_topics) # ì½˜ì†” ì¶œë ¥

        # ì£¼í”¼í„°/Colab í™˜ê²½ì—ì„œ í‘œë¡œ ì˜ˆì˜ê²Œ ì¶œë ¥
        from IPython.display import display
        display(df_topics)

        # --- C. Gemini AI ì‹¬ì¸µ ìš”ì•½ ---
        print("\nğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        full_content = " ".join(raw_texts)[:3000]
        prompt = f"ë‹¤ìŒì€ ìˆ˜ì§‘ëœ êµìœ¡/ê¸°ìˆ  ë°ì´í„°ì…ë‹ˆë‹¤. 1.í•µì‹¬ ì£¼ì œ 3ê°€ì§€ 2.í‚¤ì›Œë“œ ì—°ê´€ì„± 3.ë¯¸ë˜ ì „ë§ì„ ìš”ì•½í•´ì¤˜: {full_content}"
        response = model.generate_content(prompt)
        print("\n" + "="*50 + "\n" + response.text + "\n" + "="*50)

except Exception as e:
    print(f"â— ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
